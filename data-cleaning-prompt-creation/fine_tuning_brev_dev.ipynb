{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This jupiter notebook is a modified version of the brev.dev [notebook](\"https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb\") a huge thanks for their clear explanations ❤️",
   "id": "2477d7bbca199b8c"
  },
  {
   "cell_type": "code",
   "id": "1faf801d28d6793b",
   "metadata": {},
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib\n",
    "!pip install -q -U wandb\n",
    "!pip install -q -U pandas\n",
    "!pip install -q -U os-sys\n",
    "!pip install -q -U random2\n",
    "!pip install -q -U matplotlib\n",
    "!pip install -q -U huggingface-hub"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_csv_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),\"./data-cleaning/processed_dataset.csv\")\n",
    "df = pd.read_csv(dataset_csv_path)\n",
    "chat_list = []\n",
    "\n",
    "with open(dataset_csv_path, 'r') as file:\n",
    "    for index, row in df.iterrows():\n",
    "        print('print')\n",
    "        user_question = f\"Peux-tu m'écrire un poème en {row['Meter']} sur {row['Theme']} comme {row['Author']} dans {row['Title']} de le recueil {row['Book']} écrit en {row['Year']} ?\"\n",
    "        bot_answer = f\"Bien sûr:\\n{row['Poem']}\"\n",
    "        chat_line = f\"### Question: {user_question}\\n ### Réponse: {bot_answer}\"\n",
    "        print(chat_line)\n",
    "        if type(chat_line) is not None:\n",
    "            chat_list.append(chat_line)\n",
    "\n",
    "random.shuffle(chat_list)\n",
    "\n",
    "split_index = int(len(chat_list) * 0.8)\n",
    "\n",
    "train_list = chat_list[:split_index]\n",
    "test_list = chat_list[split_index:]\n",
    "\n",
    "train_dataframe = pd.DataFrame(train_list, columns=['text'])\n",
    "eval_dataframe = pd.DataFrame(test_list, columns=['text'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f1a2ae7db58d75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:22:58.406064Z",
     "start_time": "2024-04-27T10:22:48.688074Z"
    }
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257bece6f108e74f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacd1f68d142445aae4d5812002b0d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(\"\")\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d0353aca1add1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(prompt[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d0be06009a2a46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ea894379854654b1ba509b9239118a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5aacfef6b44dfd87f964521d4126ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataframe)\n",
    "eval_dataset = Dataset.from_pandas(eval_dataframe)\n",
    "\n",
    "###\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202180eaa33b5d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(func_tokenized_train_dataset, func_tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in func_tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in func_tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf1af97fcbc0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 516 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c33df0272ee351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9331ec7978284bda9044d9ca0b13a189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa67c5d1b7f84dceab9135716e090d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5fe8b79d20521f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 774, 22478, 28747, 3242, 1554, 28733, 17512, 290, 28742, 28797, 1381, 267, 521, 1627, 8158, 481, 1424, 267, 27922, 1147, 5625, 325, 5798, 28731, 6702, 8218, 3745, 8377, 2422, 351, 492, 6592, 449, 328, 383, 340, 462, 937, 441, 309, 4573, 5464, 27973, 340, 543, 3051, 1233, 12724, 481, 28705, 28740, 28783, 28782, 28774, 1550, 13, 774, 15417, 1405, 28747, 365, 1375, 268, 28951, 28712, 28747, 13, 28762, 28912, 363, 677, 11844, 363, 1555, 331, 4601, 5672, 363, 1771, 544, 1238, 13, 13, 28824, 1724, 28725, 3127, 440, 1415, 2248, 28725, 13662, 704, 308, 616, 14021, 1550, 13, 13, 28762, 28912, 363, 677, 11844, 363, 1555, 331, 4601, 5672, 843, 12655, 1776, 309, 1238, 13, 13, 7774, 1326, 28705, 28952, 309, 284, 2020, 4405, 1289, 305, 28742, 1752, 12764, 8012, 28718, 1550, 13, 13, 13, 28737, 4911, 363, 677, 28725, 27990, 1442, 1147, 1514, 9555, 274, 356, 2279, 28725, 13, 13, 966, 452, 14465, 634, 287, 4318, 297, 8407, 381, 340, 13662, 2753, 13, 13, 28758, 2448, 340, 3670, 8191, 465, 28725, 19255, 363, 677, 1776, 361, 634, 12471, 274, 13, 13, 28755, 2457, 15396, 3285, 347, 4601, 28725, 2120, 291, 15396, 3285, 4259, 28744, 28723, 13, 13, 13, 28755, 1555, 307, 353, 28725, 2422, 1966, 2208, 28725, 307, 28742, 24054, 507, 520, 543, 847, 24893, 13, 13, 17379, 12429, 11109, 6273, 1326, 16018, 361, 305, 804, 426, 2753, 13, 13, 11799, 462, 15004, 28725, 295, 5560, 293, 918, 6018, 1326, 22506, 1127, 408, 28876, 333, 13, 13, 28759, 28742, 374, 264, 1485, 370, 340, 3670, 1554, 526, 28742, 370, 5697, 536, 438, 424, 501, 918, 1101, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa978075b0c6c8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42d79aeaf5e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \"Peux-tu m'écrire un poème en 4 strophes sur l'amour de sa fille ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "945677a482b45c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peux-tu m'écrire un poème en 4 strophes sur l'amour de sa fille ?\n",
      " ### I.\n",
      "Lorsque je te vois, ma chère enfant,\n",
      "Ta bouche si douce et ta chevelure blonde,\n",
      "Je me sens tout à coup plus vieux que jamais ;\n",
      "Et j'ai peur d'être trop vieux pour toi !\n",
      "\n",
      "Quand tu parles, ton accent est charmant :\n",
      "Ce n'est pas encore le langage des adultes ;\n",
      "Mais déjà il y a dans tes propos\n",
      "Un air de femme qui fait trembler mon cœur.\n",
      "\n",
      "Dans les yeux bleus où se reflète la lumière,\n",
      "Il y a quelque chose de mystérieux ;\n",
      "Et quand tu souris, je ne puis m'empêcher\n",
      "De penser qu'il faut que tu sois aimée.\n",
      "\n",
      "Puisqu'on dit que l'enfance vole comme une oiseau,\n",
      "Que l'âge s'écoule sans retour,\n",
      "Ne me dis rien, ma petite amie,\n",
      "Car je suis trop sensible à tes caresses.\n",
      "\n",
      "### II.\n",
      "Si tu veux être belle, ma chère enfant,\n",
      "Sois bonne et sage, et fais ce que je te dis.\n",
      "Sous mes regards attentifs, tu seras belle ;\n",
      "Mais si tu veux être heureuse, écoute-moi.\n",
      "\n",
      "La beauté est un fleuve dont on ne peut boire ;\n",
      "Elle est un soleil dont on ne peut regarder longtemps ;\n",
      "Elle est un sonnet dont on ne peut répéter les vers ;\n",
      "Elle est un rêve dont on ne peut se souvenir.\n",
      "\n",
      "La beauté est un éclair qui brille et s'efface ;\n",
      "Elle est un arbre dont on ne peut prendre les fruits ;\n",
      "Elle est un livre dont on ne peut lire tous les pages ;\n",
      "Elle est un jour dont on ne peut garder le souvenir.\n",
      "\n",
      "La beauté est un baiser dont on ne peut se reprendre ;\n",
      "Elle est un printemps dont on ne peut conserver la fraîcheur ;\n",
      "Elle est un nuage dont on ne peut suivre le passage ;\n",
      "Elle est un rayon dont\n"
     ]
    }
   ],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=512, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1259e1db800d35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "496a1e2a495cd10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(trainable_model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in trainable_model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1acd5abc23627b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17541b1d6c17eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f65fba1dcdaf4fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba8afb53ea9b78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "711940db6abe5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e866c79d32f82f9",
   "metadata": {},
   "source": "This one needs to be stopped once there it start to overfit."
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36c42a39-724e-4aba-9c1b-130c22552f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjochum-romain\u001B[0m (\u001B[33mec-nantes\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-NLPoetry\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d35716b4d56b65e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/verb-workspace/wandb/run-20240427_133701-87ptzr0g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ec-nantes/journal-NLPoetry/runs/87ptzr0g' target=\"_blank\">mistral-journal-NLPoetry-2024-04-27-13-37</a></strong> to <a href='https://wandb.ai/ec-nantes/journal-NLPoetry' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ec-nantes/journal-NLPoetry' target=\"_blank\">https://wandb.ai/ec-nantes/journal-NLPoetry</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ec-nantes/journal-NLPoetry/runs/87ptzr0g' target=\"_blank\">https://wandb.ai/ec-nantes/journal-NLPoetry/runs/87ptzr0g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:177: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [251/500 20:17 < 20:17, 0.20 it/s, Epoch 0.39/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.043300</td>\n",
       "      <td>1.938009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.904900</td>\n",
       "      <td>1.894008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.760300</td>\n",
       "      <td>1.872517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.811700</td>\n",
       "      <td>1.855737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.794900</td>\n",
       "      <td>1.846474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.855900</td>\n",
       "      <td>1.836374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.776000</td>\n",
       "      <td>1.830369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.786800</td>\n",
       "      <td>1.821500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.775800</td>\n",
       "      <td>1.820002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/41 00:25 < 00:47, 0.54 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:177: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:177: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:177: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:177: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:177: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:177: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:177: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 37\u001B[0m\n\u001B[1;32m      9\u001B[0m trainer \u001B[38;5;241m=\u001B[39m transformers\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[1;32m     10\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     11\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mtokenized_train_dataset,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     33\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mtransformers\u001B[38;5;241m.\u001B[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m     34\u001B[0m )\n\u001B[1;32m     36\u001B[0m model\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/trainer.py:1875\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1873\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1874\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1875\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1876\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1877\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1878\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1879\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1880\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/trainer.py:2281\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2278\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m=\u001B[39m epoch \u001B[38;5;241m+\u001B[39m (step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m steps_skipped) \u001B[38;5;241m/\u001B[39m steps_in_epoch\n\u001B[1;32m   2279\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m-> 2281\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2282\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2283\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_substep_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/trainer.py:2665\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2663\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2664\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_evaluate:\n\u001B[0;32m-> 2665\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2666\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step, metrics)\n\u001B[1;32m   2668\u001B[0m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/trainer.py:3513\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3510\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3512\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[0;32m-> 3513\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3514\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3515\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3516\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[1;32m   3517\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[1;32m   3518\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3521\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3523\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[1;32m   3524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/trainer.py:3696\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3693\u001B[0m         batch_size \u001B[38;5;241m=\u001B[39m observed_batch_size\n\u001B[1;32m   3695\u001B[0m \u001B[38;5;66;03m# Prediction step\u001B[39;00m\n\u001B[0;32m-> 3696\u001B[0m loss, logits, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprediction_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3697\u001B[0m main_input_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmain_input_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   3698\u001B[0m inputs_decode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_input(inputs[main_input_name]) \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39minclude_inputs_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/trainer.py:3882\u001B[0m, in \u001B[0;36mTrainer.prediction_step\u001B[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001B[0m\n\u001B[1;32m   3880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_labels \u001B[38;5;129;01mor\u001B[39;00m loss_without_labels:\n\u001B[1;32m   3881\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3882\u001B[0m         loss, outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3883\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[1;32m   3885\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/trainer.py:3205\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   3203\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3204\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 3205\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3206\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   3207\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   3208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/accelerate/utils/operations.py:822\u001B[0m, in \u001B[0;36mconvert_outputs_to_fp32.<locals>.forward\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 822\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/accelerate/utils/operations.py:810\u001B[0m, in \u001B[0;36mConvertOutputsToFp32.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 810\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m convert_to_fp32(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001B[0m, in \u001B[0;36mautocast_decorator.<locals>.decorate_autocast\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_autocast\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[0;32m---> 16\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/peft_model.py:1304\u001B[0m, in \u001B[0;36mPeftModelForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001B[0m\n\u001B[1;32m   1302\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_peft_forward_hooks(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1303\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspecial_peft_forward_args}\n\u001B[0;32m-> 1304\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1305\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1307\u001B[0m \u001B[43m            \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1308\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1309\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1310\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1311\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1312\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1313\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m _get_batch_size(input_ids, inputs_embeds)\n\u001B[1;32m   1316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:179\u001B[0m, in \u001B[0;36mBaseTuner.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[0;32m--> 179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/accelerate/hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1158\u001B[0m, in \u001B[0;36mMistralForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1155\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   1157\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1158\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1159\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1162\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1163\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1165\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1166\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1167\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1168\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1170\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1171\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(hidden_states)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/accelerate/hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1043\u001B[0m, in \u001B[0;36mMistralModel.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1033\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1034\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m   1035\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1040\u001B[0m         use_cache,\n\u001B[1;32m   1041\u001B[0m     )\n\u001B[1;32m   1042\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1043\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1044\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1045\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1046\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1047\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1048\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1049\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1050\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1052\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1054\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/accelerate/hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:757\u001B[0m, in \u001B[0;36mMistralDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001B[0m\n\u001B[1;32m    754\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_layernorm(hidden_states)\n\u001B[1;32m    756\u001B[0m \u001B[38;5;66;03m# Self Attention\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m hidden_states, self_attn_weights, present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    758\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    759\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    761\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    763\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    764\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    765\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    767\u001B[0m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/accelerate/hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:654\u001B[0m, in \u001B[0;36mMistralSdpaAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001B[0m\n\u001B[1;32m    651\u001B[0m bsz, q_len, _ \u001B[38;5;241m=\u001B[39m hidden_states\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m    653\u001B[0m query_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_proj(hidden_states)\n\u001B[0;32m--> 654\u001B[0m key_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mk_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    655\u001B[0m value_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj(hidden_states)\n\u001B[1;32m    657\u001B[0m query_states \u001B[38;5;241m=\u001B[39m query_states\u001B[38;5;241m.\u001B[39mview(bsz, q_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:452\u001B[0m, in \u001B[0;36mLinear4bit.forward\u001B[0;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m    450\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_layer(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 452\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;66;03m# As per Tim Dettmers, for 4bit, we need to defensively clone here.\u001B[39;00m\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;66;03m# The reason is that in some cases, an error can occur that backprop\u001B[39;00m\n\u001B[1;32m    455\u001B[0m     \u001B[38;5;66;03m# does not work on a manipulated view. This issue may be solved with\u001B[39;00m\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;66;03m# newer PyTorch versions but this would need extensive testing to be\u001B[39;00m\n\u001B[1;32m    457\u001B[0m     \u001B[38;5;66;03m# sure.\u001B[39;00m\n\u001B[1;32m    458\u001B[0m     result \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mclone()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/accelerate/hooks.py:166\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[0;34m(module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m         output \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 166\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_old_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:468\u001B[0m, in \u001B[0;36mLinear4bit.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    465\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_dtype)\n\u001B[1;32m    467\u001B[0m bias \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_dtype)\n\u001B[0;32m--> 468\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mbnb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul_4bit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquant_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    470\u001B[0m out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mto(inp_dtype)\n\u001B[1;32m    472\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:579\u001B[0m, in \u001B[0;36mmatmul_4bit\u001B[0;34m(A, B, quant_state, out, bias)\u001B[0m\n\u001B[1;32m    577\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m out\n\u001B[1;32m    578\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 579\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mMatMul4Bit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_state\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/autograd/function.py:598\u001B[0m, in \u001B[0;36mFunction.apply\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[1;32m    597\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[0;32m--> 598\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[1;32m    601\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    602\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    603\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    604\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    605\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    606\u001B[0m     )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:509\u001B[0m, in \u001B[0;36mMatMul4Bit.forward\u001B[0;34m(ctx, A, B, out, bias, quant_state)\u001B[0m\n\u001B[1;32m    505\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mempty(A\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m B_shape[:\u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mA\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mA\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    507\u001B[0m \u001B[38;5;66;03m# 1. Dequantize\u001B[39;00m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;66;03m# 2. MatmulnN\u001B[39;00m\n\u001B[0;32m--> 509\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdequantize_4bit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_state\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;66;03m# 3. Save state\u001B[39;00m\n\u001B[1;32m    512\u001B[0m ctx\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m quant_state\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"journal-NLPoetry\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a953c58c88331",
   "metadata": {},
   "source": "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to Kernel > Restart Kernel or kill the process via the Terminal (nvidia smi > kill [PID])."
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fef1077487340e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252215dda6064ce7b03805e5b0f2f6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d655b5999caba96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, f\"{run_name}/checkpoint-225\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf4bee9b8bc15d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peux-tu m'écrire un poème en 4 strophes sur l'amour de sa fille ?\n",
      " ### I.\n",
      "Lorsque je te vois, ma chère enfant,\n",
      "Ta bouche si douce et ta chevelure blonde,\n",
      "Je me sens tout à coup plus vieux que jamais ;\n",
      "Et j'ai peur d'aimer trop ce qui t'appartient !\n",
      "\n",
      "### II.\n",
      "Mais tu ne comprends pas mon inquiétude :\n",
      "Ce n'est qu'un sentiment de tendresse paternelle,\n",
      "Qui seul peut rendre heureuse une mère fidèle,\n",
      "Et faire grandir son cœur dans la bonne foi.\n",
      "\n",
      "### III.\n",
      "Quand tu seras grande, ma petite amie,\n",
      "J'espère que tu m'en aimeras toujours,\n",
      "Comme je t'aime aujourd'hui, et comme je t'aimerai demain.\n",
      "\n",
      "### IV.\n",
      "Puisque tu es belle, ma chère enfant,\n",
      "Que ton père soit le premier à te dire :\n",
      "« Tu es belle, ma chère enfant,\n",
      "Et je suis fier de toi ! »\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"Peux-tu m'écrire un poème en 4 strophes sur l'amour de sa fille ?\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=512, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8ac5dd8499ea764",
   "metadata": {},
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dde2eaede4fb5a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_id = \"Romain-Jochum/Mistral_7B_French_Poetry_Tuning\"\n",
    "model.push_to_hub(peft_model_id, token=True, save_embedding_layers=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
